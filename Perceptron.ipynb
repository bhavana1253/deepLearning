{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f653c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "34bf62a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_table('https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/diabetes_scale',\n",
    "              sep=r'\\s+\\d+:', engine='python', header=None).loc[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9d4f9bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>-0.294118</td>\n",
       "      <td>0.487437</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>-0.292929</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.001490</td>\n",
       "      <td>-0.531170</td>\n",
       "      <td>-0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.882353</td>\n",
       "      <td>-0.145729</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>-0.414141</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.207153</td>\n",
       "      <td>-0.766866</td>\n",
       "      <td>-0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>-0.058824</td>\n",
       "      <td>0.839196</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.305514</td>\n",
       "      <td>-0.492741</td>\n",
       "      <td>-0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.882353</td>\n",
       "      <td>-0.105528</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>-0.535354</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>-0.162444</td>\n",
       "      <td>-0.923997</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.376884</td>\n",
       "      <td>-0.344262</td>\n",
       "      <td>-0.292929</td>\n",
       "      <td>-0.602837</td>\n",
       "      <td>0.284650</td>\n",
       "      <td>0.887276</td>\n",
       "      <td>-0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>1</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.015075</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>-0.030303</td>\n",
       "      <td>-0.574468</td>\n",
       "      <td>-0.019374</td>\n",
       "      <td>-0.920581</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.764706</td>\n",
       "      <td>0.226131</td>\n",
       "      <td>0.147541</td>\n",
       "      <td>-0.454545</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.096870</td>\n",
       "      <td>-0.776260</td>\n",
       "      <td>-0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.411765</td>\n",
       "      <td>0.216080</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>-0.535354</td>\n",
       "      <td>-0.735225</td>\n",
       "      <td>-0.219076</td>\n",
       "      <td>-0.857387</td>\n",
       "      <td>-0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>-1</td>\n",
       "      <td>-0.882353</td>\n",
       "      <td>0.266332</td>\n",
       "      <td>-0.016393</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.102832</td>\n",
       "      <td>-0.768574</td>\n",
       "      <td>-0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.882353</td>\n",
       "      <td>-0.065327</td>\n",
       "      <td>0.147541</td>\n",
       "      <td>-0.373737</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.093890</td>\n",
       "      <td>-0.797609</td>\n",
       "      <td>-0.933333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2         3         4         5         6         7  \\\n",
       "0   -1 -0.294118  0.487437  0.180328 -0.292929 -1.000000  0.001490 -0.531170   \n",
       "1    1 -0.882353 -0.145729  0.081967 -0.414141 -1.000000 -0.207153 -0.766866   \n",
       "2   -1 -0.058824  0.839196  0.049180 -1.000000 -1.000000 -0.305514 -0.492741   \n",
       "3    1 -0.882353 -0.105528  0.081967 -0.535354 -0.777778 -0.162444 -0.923997   \n",
       "4   -1 -1.000000  0.376884 -0.344262 -0.292929 -0.602837  0.284650  0.887276   \n",
       "..  ..       ...       ...       ...       ...       ...       ...       ...   \n",
       "763  1  0.176471  0.015075  0.245902 -0.030303 -0.574468 -0.019374 -0.920581   \n",
       "764  1 -0.764706  0.226131  0.147541 -0.454545 -1.000000  0.096870 -0.776260   \n",
       "765  1 -0.411765  0.216080  0.180328 -0.535354 -0.735225 -0.219076 -0.857387   \n",
       "766 -1 -0.882353  0.266332 -0.016393 -1.000000 -1.000000 -0.102832 -0.768574   \n",
       "767  1 -0.882353 -0.065327  0.147541 -0.373737 -1.000000 -0.093890 -0.797609   \n",
       "\n",
       "            8  \n",
       "0   -0.033333  \n",
       "1   -0.666667  \n",
       "2   -0.633333  \n",
       "3   -1.000000  \n",
       "4   -0.600000  \n",
       "..        ...  \n",
       "763  0.400000  \n",
       "764 -0.800000  \n",
       "765 -0.700000  \n",
       "766 -0.133333  \n",
       "767 -0.933333  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "81d6223f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       768 non-null    int64  \n",
      " 1   1       768 non-null    float64\n",
      " 2   2       768 non-null    float64\n",
      " 3   3       768 non-null    float64\n",
      " 4   4       768 non-null    float64\n",
      " 5   5       768 non-null    float64\n",
      " 6   6       768 non-null    float64\n",
      " 7   7       768 non-null    float64\n",
      " 8   8       759 non-null    float64\n",
      "dtypes: float64(8), int64(1)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dbaf49fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "5    0\n",
       "6    0\n",
       "7    0\n",
       "8    9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8f72cb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "98272bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     -1\n",
       "1      1\n",
       "2     -1\n",
       "3      1\n",
       "4     -1\n",
       "      ..\n",
       "763    1\n",
       "764    1\n",
       "765    1\n",
       "766   -1\n",
       "767    1\n",
       "Name: 0, Length: 768, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing train_test_split from sklearn library\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "X=df.loc[:,1:]\n",
    "X\n",
    "y= df.iloc[:,0]\n",
    "y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7d85b170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='0', ylabel='count'>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.countplot(x=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "aec1d9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (537, 8)\n",
      "y_train shape:  (537,)\n",
      "X_test shape:  (231, 8)\n",
      "y_test shape:  (231,)\n"
     ]
    }
   ],
   "source": [
    "# TRAIN and TEST SPLIT\n",
    "def split(X,y):\n",
    "    return train_test_split(X, y, test_size=0.30, random_state=2)\n",
    "\n",
    "X_train, X_test, y_train, y_test=split(X,y)\n",
    "\n",
    "print('X_train shape: ',X_train.shape)\n",
    "print('y_train shape: ',y_train.shape)\n",
    "\n",
    "print('X_test shape: ',X_test.shape)\n",
    "print('y_test shape: ',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2bd1299d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(random_state=42)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "p = Perceptron(random_state=42)\n",
    "p.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9b44b003",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= p.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6ac38fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  1\n",
      "expected - -1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  -1\n",
      "expected - -1 predicted -  -1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  -1\n",
      "expected - 1 predicted -  -1\n",
      "expected - -1 predicted -  -1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  1\n",
      "expected - -1 predicted -  -1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  -1\n",
      "expected - 1 predicted -  -1\n",
      "expected - 1 predicted -  -1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  1\n",
      "expected - -1 predicted -  -1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  -1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  -1\n",
      "expected - -1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  -1\n",
      "expected - -1 predicted -  1\n",
      "expected - 1 predicted -  -1\n",
      "expected - -1 predicted -  -1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  -1\n",
      "expected - -1 predicted -  -1\n",
      "expected - -1 predicted -  -1\n",
      "expected - -1 predicted -  -1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  -1\n",
      "expected - 1 predicted -  -1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  -1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  1\n",
      "expected - 1 predicted -  -1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  1\n",
      "expected - 1 predicted -  -1\n",
      "expected - -1 predicted -  1\n",
      "expected - 1 predicted -  -1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  1\n",
      "expected - -1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  -1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  1\n",
      "expected - -1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  -1\n",
      "expected - 1 predicted -  -1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  -1\n",
      "expected - -1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  1\n",
      "expected - -1 predicted -  -1\n",
      "expected - 1 predicted -  -1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  -1\n",
      "expected - -1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  -1\n",
      "expected - -1 predicted -  1\n",
      "expected - 1 predicted -  -1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  -1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  -1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  -1\n",
      "expected - -1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  -1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  1\n",
      "expected - -1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  -1\n",
      "expected - -1 predicted -  -1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  1\n",
      "expected - -1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  -1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  1\n",
      "expected - -1 predicted -  1\n",
      "expected - -1 predicted -  1\n",
      "expected - -1 predicted -  1\n",
      "expected - -1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  1\n",
      "expected - -1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  1\n",
      "expected - -1 predicted -  1\n",
      "expected - -1 predicted -  -1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  -1\n",
      "expected - 1 predicted -  -1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  -1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  1\n",
      "expected - -1 predicted -  -1\n",
      "expected - -1 predicted -  -1\n",
      "expected - -1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  1\n",
      "expected - 1 predicted -  1\n",
      "expected - -1 predicted -  1\n",
      "expected - -1 predicted -  -1\n",
      "expected - 1 predicted -  -1\n",
      "expected - 1 predicted -  1\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_test)):\n",
    "    print(\"expected -\",y_test.iloc[i],\"predicted - \",y_pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a32d99a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7272727272727273"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1070b1b",
   "metadata": {},
   "source": [
    "Lets implement our own percepron "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "9cb75e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights [-0.11647062 -0.02804022  0.03245904 -0.0636363  -0.18        0.01958274\n",
      " -0.15094782 -0.13800006]\n",
      "weights [-0.  0.  0. -0. -0. -0.  0. -0.]\n",
      "weights [ 0.03176478 -0.01356784  0.00295081 -0.18       -0.18       -0.04104324\n",
      " -0.16631946 -0.12000006]\n",
      "weights [ 0.13764708 -0.1058292  -0.0855738   0.18        0.18        0.010462\n",
      "  0.06824934 -0.09      ]\n",
      "weights [ 0.03176478  0.0714573   0.0560655  -0.18       -0.18       -0.034605\n",
      "  0.02951316  0.036     ]\n",
      "weights [ 0.05294124 -0.06241212 -0.02655738  0.09636372  0.12468078 -0.00992551\n",
      "  0.10867626  0.13199994]\n",
      "weights [-0. -0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.15882354 -0.05155776  0.05016402  0.00181818 -0.16085106 -0.00187778\n",
      " -0.12712212 -0.18      ]\n",
      "weights [-0.01058823 -0.05517594 -0.02655738  0.18        0.18       -0.00348734\n",
      "  0.09176778  0.036     ]\n",
      "weights [-0.15882354  0.02261304  0.03245904 -0.07090902 -0.10510632  0.00456037\n",
      " -0.11082834 -0.15600006]\n",
      "weights [ 0.13764708 -0.0334674  -0.0560655   0.18        0.18       -0.05016402\n",
      "  0.08546544  0.18      ]\n",
      "weights [-0.18        0.08412066  0.06196716 -0.18       -0.18        0.03728772\n",
      "  0.08177634 -0.04199994]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.15882354  0.09316584 -0.00295081 -0.18       -0.18       -0.03997026\n",
      " -0.16447482 -0.17400006]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0.  0.]\n",
      "weights [ 0.01058823  0.04432158  0.02655738 -0.05999994 -0.00893617  0.00992551\n",
      " -0.1486422  -0.10200006]\n",
      "weights [-0. -0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.03176478  0.00452261  0.0383607  -0.03454542 -0.13531914  0.01958274\n",
      " -0.160632   -0.036     ]\n",
      "weights [ 0.01058823 -0.12211056 -0.1327869   0.01272728  0.08170218 -0.0217287\n",
      "  0.1666269   0.04800006]\n",
      "weights [-0.13764708  0.01537688  0.00295081 -0.1436364  -0.0617022  -0.04426236\n",
      " -0.05656698 -0.17400006]\n",
      "weights [-0. -0. -0. -0. -0.  0. -0. -0.]\n",
      "weights [ 0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.0741177  -0.0388944  -0.0383607  -0.18       -0.18        0.00080478\n",
      " -0.09146034 -0.15600006]\n",
      "weights [ 0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.0741177  -0.00090452 -0.02065572 -0.07818174 -0.14468094  0.0024143\n",
      " -0.11528604 -0.126     ]\n",
      "weights [-0.  0. -0. -0. -0.  0. -0. -0.]\n",
      "weights [ 0.01058823 -0.01537688  0.02065572 -0.18       -0.18       -0.05016384\n",
      " -0.16124688  0.04199994]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.15882354  0.01718593 -0.00885245 -0.11454552 -0.13063824 -0.02709396\n",
      " -0.1583262  -0.17400006]\n",
      "weights [-0. -0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.13764708 -0.00633166  0.02065572 -0.13272732 -0.15914898 -0.06679584\n",
      " -0.09253638 -0.14999994]\n",
      "weights [ 0.03176478 -0.09497484 -0.07967214  0.01999998  0.18       -0.08825634\n",
      "  0.14018796  0.09      ]\n",
      "weights [-0.0741177   0.00994975  0.03245904 -0.07454538 -0.04170204  0.0179732\n",
      " -0.16754904 -0.13800006]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.13764708 -0.02804022 -0.18       -0.18       -0.18       -0.18\n",
      " -0.14526054 -0.18      ]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.01058823 -0.0081407   0.03245904 -0.18       -0.18        0.01743665\n",
      " -0.11743812  0.036     ]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [ 0.  0. -0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.15882354  0.01356784 -0.03245904 -0.11090916 -0.18       -0.02816694\n",
      " -0.16416738 -0.13199994]\n",
      "weights [ 0.09529416 -0.03165822 -0.00295081  0.13636368  0.18        0.02065572\n",
      "  0.13357818  0.126     ]\n",
      "weights [ 0. -0.  0. -0. -0.  0. -0.  0.]\n",
      "weights [-0. -0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.15882354  0.02080404  0.07377048 -0.11090916 -0.18       -0.01850976\n",
      " -0.17000856 -0.16799994]\n",
      "weights [ 0.01058823 -0.13839192 -0.0855738   0.05636358  0.0523404  -0.00080478\n",
      "  0.1202049  -0.04199994]\n",
      "weights [-0.01058823 -0.02623122 -0.01770493 -0.1072728  -0.18       -0.04909086\n",
      " -0.1710846  -0.054     ]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.  0. -0. -0. -0. -0. -0. -0.]\n",
      "weights [ 0. -0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [ 0.03176478  0.05336676  0.04426236 -0.07818174 -0.12808512  0.01260806\n",
      " -0.14894964 -0.072     ]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0.  0.]\n",
      "weights [-0.13764708 -0.05698494  0.00295081 -0.13272732 -0.17361702 -0.07216092\n",
      " -0.15248502 -0.16799994]\n",
      "weights [-0. -0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.13764708  0.0370854   0.04426236 -0.0454545  -0.13531914  0.03299562\n",
      " -0.15894108 -0.13199994]\n",
      "weights [ 0.11647062 -0.12572856 -0.0383607   0.11090916  0.12680856  0.01958274\n",
      "  0.15079428  0.12000006]\n",
      "weights [-0.0741177  -0.02080404  0.0147541  -0.10363644 -0.17021268 -0.04909086\n",
      " -0.13941936 -0.126     ]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.18        0.0081407   0.04426236 -0.18       -0.18       -0.0812817\n",
      " -0.10252782 -0.144     ]\n",
      "weights [ 0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [ 0.09529416  0.08231148  0.06196716 -0.11090916 -0.13319154 -0.06089418\n",
      " -0.15432966  0.036     ]\n",
      "weights [ 0.18       -0.0750753   0.18        0.18        0.18       -0.0474813\n",
      "  0.16047828  0.13199994]\n",
      "weights [-0.0741177  -0.00633166  0.0383607  -0.11454552 -0.15148944  0.00026825\n",
      " -0.03873618 -0.04800006]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.15882354 -0.0334674   0.03245904 -0.11454552 -0.16297866 -0.03728754\n",
      " -0.14848848 -0.162     ]\n",
      "weights [ 0.03176478 -0.01175879  0.00295081  0.09272736  0.18        0.03782412\n",
      "  0.14649012  0.13199994]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.01058823  0.00090452  0.04426236 -0.18       -0.18        0.02763036\n",
      " -0.1627839  -0.054     ]\n",
      "weights [-0.18       -0.11487438 -0.03245904  0.03090906  0.13148928 -0.03943368\n",
      "  0.0664047   0.02399994]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.15882354 -0.01899504  0.04426236 -0.05636358 -0.1642554  -0.01260805\n",
      " -0.16247646 -0.16799994]\n",
      "weights [-0.01058823 -0.02261304 -0.06196716  0.09272736  0.18        0.02870334\n",
      " -0.00507258  0.00599999]\n",
      "weights [-0.15882354  0.02261304  0.0560655  -0.01636364 -0.12382974  0.0067064\n",
      " -0.15863364 -0.162     ]\n",
      "weights [ 0.05294124 -0.08592966 -0.0560655   0.18        0.18        0.0217287\n",
      "  0.16462854  0.00599999]\n",
      "weights [-0.09529416 -0.0081407   0.02655738 -0.0636363  -0.18       -0.00777944\n",
      " -0.0979164  -0.162     ]\n",
      "weights [-0.  0. -0. -0. -0. -0. -0.  0.]\n",
      "weights [-0.15882354  0.01175879  0.04426236 -0.18       -0.18        0.0211923\n",
      " -0.16170786 -0.14999994]\n",
      "weights [-0.  0.  0. -0. -0. -0.  0. -0.]\n",
      "weights [ 0.03176478  0.11306538  0.06786882 -0.18       -0.18       -0.03138606\n",
      " -0.16401366  0.018     ]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.18        0.0714573   0.00295081 -0.11818188 -0.09063828 -0.06143076\n",
      " -0.16017084 -0.18      ]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.15882354 -0.00452261  0.02065572 -0.10363644 -0.18       -0.0340686\n",
      " -0.02367216 -0.17400006]\n",
      "weights [-0. -0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.  0.  0. -0.  0.  0.  0. -0.]\n",
      "weights [-0.0741177   0.03165822  0.07377048 -0.07090902 -0.13531914  0.0297765\n",
      " -0.15340734 -0.054     ]\n",
      "weights [-0.05294124 -0.07869348 -0.09737712  0.05999994  0.11787228 -0.01636364\n",
      "  0.15294618 -0.        ]\n",
      "weights [-0.18        0.1112562  -0.03245904 -0.18       -0.18       -0.06250374\n",
      " -0.15294618  0.08400006]\n",
      "weights [ 0.01058823 -0.0370854   0.18        0.18        0.18        0.01904616\n",
      "  0.16385994  0.07799994]\n",
      "weights [-0.09529416 -0.02804022  0.0855738  -0.09636372 -0.15617016  0.03192246\n",
      " -0.16754904 -0.15600006]\n",
      "weights [ 0.15882354 -0.12211056 -0.0383607   0.11818188  0.11872332  0.05445612\n",
      "  0.1232793   0.108     ]\n",
      "weights [-0.15882354  0.06603012  0.0383607   0.00181818 -0.0931914   0.02065572\n",
      " -0.1306575  -0.162     ]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.13764708  0.07688448  0.06196716 -0.11454552 -0.152766   -0.0474813\n",
      " -0.07501284 -0.18      ]\n",
      "weights [-0.  0. -0. -0. -0. -0. -0.  0.]\n",
      "weights [-0.05294124  0.04613058  0.02065572 -0.07090902 -0.12893616 -0.01904616\n",
      " -0.12066606 -0.11399994]\n",
      "weights [ 0.13764708  0.01175879 -0.00885245  0.0636363   0.11191482 -0.02387484\n",
      "  0.08838594  0.16799994]\n",
      "weights [ 0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.18        0.00452261 -0.02655738 -0.18       -0.18       -0.04533534\n",
      " -0.18       -0.18      ]\n",
      "weights [ 0.13764708 -0.05155776 -0.05016402  0.0454545   0.1025532  -0.05230998\n",
      "  0.00384287  0.12000006]\n",
      "weights [-0.18        0.02442204  0.0560655  -0.12181824 -0.18       -0.01368106\n",
      " -0.05764302 -0.18      ]\n",
      "weights [-0. -0. -0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.15882354  0.01718593 -0.00295081 -0.15090912 -0.1025532  -0.04372578\n",
      " -0.04642182 -0.18      ]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.0741177   0.01899504  0.02065572 -0.18       -0.18       -0.04050666\n",
      " -0.147105   -0.126     ]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.09529416  0.02984922  0.03245904 -0.13636368 -0.14297868 -0.06143076\n",
      " -0.12081978 -0.08400006]\n",
      "weights [-0.  0. -0. -0. -0. -0. -0. -0.]\n",
      "weights [ 0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.13764708 -0.00090452 -0.18       -0.18       -0.18       -0.06089418\n",
      " -0.17538858 -0.16799994]\n",
      "weights [-0. -0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.15882354  0.08050248  0.06196716 -0.03454542 -0.18        0.04157982\n",
      " -0.09868482 -0.13800006]\n",
      "weights [-0. -0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.  0. -0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.15882354 -0.01175879  0.02655738 -0.06727266 -0.18       -0.01690015\n",
      " -0.14356962 -0.16799994]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.11647062  0.01537688  0.00295081 -0.09272736 -0.18       -0.04050666\n",
      " -0.15771132 -0.15600006]\n",
      "weights [ 0. -0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.13764708 -0.00090452 -0.00295081 -0.11818188 -0.11191482  0.01636364\n",
      " -0.12235698 -0.18      ]\n",
      "weights [-0.  0. -0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.11647062 -0.00633166  0.05016402 -0.03818178 -0.18        0.02011914\n",
      " -0.1554057  -0.06600006]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.  0.  0. -0.  0.  0. -0. -0.]\n",
      "weights [ 0.09529416 -0.04251258 -0.00295081 -0.18       -0.18       -0.00402385\n",
      " -0.1643211  -0.05999994]\n",
      "weights [-0. -0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.0741177   0.02984922  0.0383607  -0.18       -0.18       -0.0426528\n",
      " -0.16109316 -0.126     ]\n",
      "weights [-0.  0. -0. -0. -0. -0. -0.  0.]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0.  0.]\n",
      "weights [-0.09529416  0.08412066  0.07081974 -0.0818181  -0.13744674 -0.02494782\n",
      " -0.16293762 -0.144     ]\n",
      "weights [ 0.0741177  -0.12030156 -0.03245904  0.11090916  0.10553184  0.04157982\n",
      "  0.10175922 -0.        ]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0.  0.]\n",
      "weights [-0.  0. -0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.18        0.01537688  0.02065572 -0.1072728  -0.18       -0.03353202\n",
      " -0.0710163  -0.11399994]\n",
      "weights [-0.  0. -0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.09529416  0.09859302  0.03245904 -0.07454538 -0.12638304 -0.01207154\n",
      " -0.14003424 -0.08400006]\n",
      "weights [ 0.18       -0.06783912  0.06196716  0.05272722  0.10851066 -0.051237\n",
      " -0.15970968  0.108     ]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [ 0.0741177   0.0388944   0.05016402 -0.11818188 -0.18       -0.03782412\n",
      " -0.15217758  0.06600006]\n",
      "weights [-0. -0. -0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0.  0.]\n",
      "weights [-0.  0. -0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.0741177   0.0714573   0.00885245 -0.05272722 -0.12042558 -0.02655738\n",
      " -0.12881304 -0.14999994]\n",
      "weights [-0. -0. -0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [ 0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0. -0.  0. -0.]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.0741177   0.04070358  0.07377048 -0.18       -0.18        0.00616991\n",
      " -0.14741244 -0.108     ]\n",
      "weights [ 0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.11647062  0.08773866  0.0147541  -0.08909082 -0.18       -0.00563337\n",
      " -0.15263874 -0.17400006]\n",
      "weights [-0.01058823 -0.10221102 -0.07377048  0.18        0.18        0.0469449\n",
      "  0.15663528 -0.01200001]\n",
      "weights [-0.15882354 -0.00090452  0.03245904 -0.07090902 -0.17234046  0.02709396\n",
      " -0.12865932 -0.18      ]\n",
      "weights [-0. -0. -0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [ 0.  0.  0. -0. -0.  0. -0.  0.]\n",
      "weights [-0.18        0.11849238  0.0855738  -0.05999994  0.1093617   0.10059606\n",
      " -0.12635352 -0.16799994]\n",
      "weights [-0.  0. -0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.0741177  -0.02442204  0.02065572 -0.07818174 -0.14978718 -0.01797316\n",
      " -0.13603752 -0.162     ]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.15882354 -0.02804022  0.00885245 -0.09636372 -0.13106376  0.0179732\n",
      " -0.11959002 -0.13800006]\n",
      "weights [-0.  0.  0.  0. -0.  0. -0. -0.]\n",
      "weights [-0.13764708  0.02261304  0.07377048 -0.0272727  -0.11191482  0.0260208\n",
      " -0.15417594 -0.13800006]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.0741177   0.04251258  0.0383607  -0.03454542 -0.14723406  0.00295081\n",
      " -0.15064056 -0.13800006]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.15882354  0.00090452  0.0383607  -0.13636368 -0.16042554 -0.07538004\n",
      " -0.16908624 -0.13800006]\n",
      "weights [-0. -0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.  0. -0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.09529416  0.16190946  0.14459022 -0.06727266 -0.18       -0.02709396\n",
      " -0.08746362 -0.08400006]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [ 0.01058823  0.04251258  0.02655738 -0.01999998 -0.14000004 -0.0024143\n",
      " -0.1345005  -0.06600006]\n",
      "weights [ 0.09529416 -0.15286428 -0.05016402  0.03818178  0.06212772 -0.01850976\n",
      "  0.15140898  0.12000006]\n",
      "weights [-0.09529416  0.02623122  0.01180328 -0.18       -0.18       -0.06250374\n",
      " -0.12558492 -0.08400006]\n",
      "weights [ 0.0741177  -0.05517594 -0.06196716  0.18        0.18       -0.0297765\n",
      "  0.04503834  0.08400006]\n",
      "weights [-0.15882354  0.0732663   0.0383607  -0.08545446 -0.10340424 -0.05070042\n",
      " -0.06471396 -0.16799994]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.  0. -0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.11647062  0.02080404 -0.0147541  -0.03818178 -0.18       -0.01850976\n",
      " -0.10637064 -0.126     ]\n",
      "weights [ 0.09529416 -0.08412066 -0.05016402  0.18        0.18       -0.02655738\n",
      "  0.1120581  -0.09599994]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.11647062  0.1058292   0.00885245 -0.13272732 -0.01531915 -0.01260805\n",
      " -0.14664384 -0.162     ]\n",
      "weights [ 0.18       -0.16010046 -0.06196716  0.12909096  0.10127664  0.00831595\n",
      "  0.08715636  0.17400006]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.0741177   0.03165822  0.09147546 -0.18       -0.18        0.00295081\n",
      " -0.14018796 -0.07799994]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.18       -0.07688448 -0.00295081 -0.18       -0.18       -0.06357672\n",
      " -0.07900938  0.09599994]\n",
      "weights [ 0.13764708 -0.00090452 -0.0147541   0.1072728   0.14170212  0.00348732\n",
      "  0.05871906  0.13800006]\n",
      "weights [ 0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.18       -0.00452261  0.00885245 -0.04909086 -0.13744674  0.01743665\n",
      " -0.09976086 -0.15600006]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.09529416 -0.01718593  0.07967214 -0.00909092 -0.1570212   0.02226528\n",
      " -0.13634496 -0.13199994]\n",
      "weights [ 0.11647062 -0.0388944   0.02655738  0.18        0.18       -0.01314457\n",
      "  0.1724679   0.15600006]\n",
      "weights [-0.13764708  0.02080404 -0.00295081 -0.18       -0.18       -0.03943368\n",
      " -0.13926564 -0.16799994]\n",
      "weights [-0.0741177  -0.09316584 -0.02655738  0.03454542  0.06468084 -0.04426236\n",
      "  0.07793334  0.07799994]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.0741177   0.10040202  0.06786882 -0.01999998  0.05191488  0.02763036\n",
      " -0.09684036 -0.10200006]\n",
      "weights [-0. -0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.15882354  0.00994975 -0.00885245 -0.18       -0.18       -0.04962744\n",
      " -0.16324506 -0.18      ]\n",
      "weights [ 0.03176478 -0.07688448 -0.0855738   0.09272736 -0.02425536  0.01690015\n",
      "  0.17231418  0.04800006]\n",
      "weights [-0.  0. -0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.  0.  0. -0.  0.  0. -0. -0.]\n",
      "weights [-0. -0.  0. -0. -0.  0.  0. -0.]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.13764708 -0.05698494  0.02655738 -0.0636363  -0.15191496 -0.04587174\n",
      " -0.16324506 -0.15600006]\n",
      "weights [-0. -0. -0. -0. -0. -0.  0. -0.]\n",
      "weights [-0.15882354 -0.00452261  0.0147541  -0.1254546  -0.12042558 -0.0555291\n",
      " -0.11713068 -0.17400006]\n",
      "weights [ 0.13764708 -0.06241212 -0.02655738  0.18        0.18        0.02494782\n",
      "  0.10867626  0.16799994]\n",
      "weights [-0.18        0.0081407   0.00885245 -0.09636372 -0.13063824 -0.03084948\n",
      " -0.12220326 -0.16799994]\n",
      "weights [-0. -0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.13764708  0.04974876 -0.00885245 -0.09272736 -0.06297876 -0.03138606\n",
      "  0.05395392 -0.15600006]\n",
      "weights [-0. -0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.09529416  0.17638182  0.02655738 -0.03818178  0.1365957   0.01690016\n",
      "  0.16601202 -0.12000006]\n",
      "weights [-0.18        0.0352764   0.0147541  -0.0818181  -0.18        0.02816694\n",
      " -0.15217758 -0.17400006]\n",
      "weights [-0.  0. -0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.11647062  0.02080404  0.0855738  -0.13636368 -0.14680854 -0.02763036\n",
      " -0.11590092 -0.13199994]\n",
      "weights [-0.  0.  0. -0. -0. -0.  0. -0.]\n",
      "weights [-0.03176478  0.06603012  0.0383607  -0.08545446 -0.12255318 -0.04050666\n",
      " -0.09253638  0.        ]\n",
      "weights [-0.01058823 -0.02261304 -0.06196716  0.0636363   0.10553184 -0.00348734\n",
      "  0.15202386  0.09      ]\n",
      "weights [-0.  0.  0. -0.  0.  0. -0. -0.]\n",
      "weights [-0.15882354  0.02080404  0.09737712 -0.18       -0.18       -0.00402385\n",
      " -0.15125526 -0.036     ]\n",
      "weights [-0. -0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.15882354 -0.02984922  0.02065572 -0.18       -0.18       -0.08235468\n",
      " -0.09607176 -0.144     ]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.15882354 -0.01718593  0.00295081 -0.11454552 -0.1548936  -0.04533534\n",
      "  0.00292057 -0.15600006]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [ 0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0.  0.]\n",
      "weights [-0.15882354 -0.00633166  0.18       -0.18       -0.18       -0.0598212\n",
      " -0.16017084 -0.144     ]\n",
      "weights [-0. -0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.05294124 -0.01537688 -0.18       -0.18       -0.18       -0.02011914\n",
      " -0.1149786  -0.12000006]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.11647062  0.00090452  0.02065572 -0.09636372 -0.14553198 -0.010462\n",
      " -0.04611438 -0.13800006]\n",
      "weights [ 0.18       -0.0081407  -0.00885245  0.0454545   0.152766   -0.00026825\n",
      "  0.1135953   0.17400006]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0.  0.]\n",
      "weights [ 0.  0.  0. -0. -0. -0.  0.  0.]\n",
      "weights [-0.03176478  0.01175879  0.09147546 -0.11454552 -0.18       -0.05821164\n",
      " -0.15586686 -0.018     ]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [ 0. -0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.15882354 -0.01537688 -0.02065572 -0.08909082 -0.13744674 -0.04479876\n",
      " -0.15602058 -0.16799994]\n",
      "weights [ 0.09529416 -0.1058292  -0.05016402  0.18        0.18        0.00348732\n",
      "  0.06855678  0.12000006]\n",
      "weights [-0.15882354 -0.0352764  -0.01770493 -0.18       -0.18       -0.077526\n",
      " -0.1523313  -0.18      ]\n",
      "weights [-0. -0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [ 0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.09529416  0.00633166 -0.00295081 -0.05999994 -0.09829782 -0.051237\n",
      " -0.04350132 -0.108     ]\n",
      "weights [ 0.03176478 -0.12391956 -0.07967214  0.0272727   0.0434043  -0.02494782\n",
      "  0.0710163   0.06600006]\n",
      "weights [-0.18        0.0750753   0.06786882 -0.08545446 -0.18       -0.00616988\n",
      " -0.1254312  -0.17400006]\n",
      "weights [-0. -0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.18        0.06422112  0.09737712 -0.01272728 -0.1182978   0.03782412\n",
      " -0.14833476 -0.14999994]\n",
      "weights [ 0.01058823 -0.1474371  -0.02065572  0.04909086 -0.03063834  0.01850976\n",
      "  0.09745524 -0.054     ]\n",
      "weights [-0.18        0.06241212 -0.00885245 -0.1072728  -0.05617026 -0.0383607\n",
      " -0.13788216 -0.18      ]\n",
      "weights [-0.  0. -0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.15882354 -0.00452261  0.00885245 -0.11090916 -0.14510646 -0.08235468\n",
      " -0.14602896 -0.18      ]\n",
      "weights [-0. -0. -0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.  0. -0. -0. -0. -0. -0. -0.]\n",
      "weights [ 0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.15882354 -0.01718593  0.00295081 -0.13636368 -0.1617021  -0.0340686\n",
      " -0.10283526 -0.162     ]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0.  0.]\n",
      "weights [-0.09529416 -0.00452261 -0.00295081 -0.09636372 -0.18       -0.02870334\n",
      " -0.12389418 -0.17400006]\n",
      "weights [-0. -0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.18        0.02623122  0.0560655  -0.05636358 -0.05872338  0.05713866\n",
      " -0.16631946 -0.144     ]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.15882354  0.02984922  0.05016402 -0.07454538 -0.10340424  0.01368106\n",
      " -0.1157472  -0.15600006]\n",
      "weights [-0.  0. -0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.05294124 -0.01175879 -0.03245904 -0.07090902 -0.152766   -0.0260208\n",
      " -0.13726728 -0.16799994]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0. -0. -0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.05294124  0.03165822  0.1032786  -0.18       -0.18       -0.0260208\n",
      " -0.16785648 -0.126     ]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.18        0.03165822  0.0560655  -0.06727266 -0.15744672  0.06250374\n",
      " -0.17830908 -0.162     ]\n",
      "weights [ 0.09529416 -0.04251258 -0.00295081  0.18        0.18        0.00831595\n",
      "  0.15725016  0.09599994]\n",
      "weights [-0.11647062 -0.0334674   0.07377048 -0.12181824 -0.15191496 -0.03245904\n",
      " -0.1449531  -0.17400006]\n",
      "weights [-0. -0.  0.  0. -0.  0. -0. -0.]\n",
      "weights [ 0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.15882354  0.03165822 -0.00295081 -0.09636372 -0.13489362  0.00134128\n",
      " -0.12035862 -0.144     ]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [ 0.01058823 -0.04974876  0.05016402 -0.08909082 -0.18       -0.010462\n",
      " -0.14894964 -0.07799994]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0.  0.]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.  0. -0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.11647062  0.16552764  0.02065572 -0.1254546  -0.12468078 -0.01421759\n",
      " -0.14602896 -0.10200006]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [ 0.05294124  0.04974876  0.1327869  -0.18       -0.18        0.02923992\n",
      " -0.1627839   0.        ]\n",
      "weights [-0.03176478 -0.12391956 -0.0383607   0.18        0.18       -0.02387484\n",
      "  0.10944486  0.10200006]\n",
      "weights [-0.18        0.04613058  0.02065572 -0.18       -0.18       -0.0474813\n",
      " -0.16032456 -0.18      ]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.05294124  0.09859302  0.05016402 -0.03090906 -0.12042558  0.06733242\n",
      " -0.10421856 -0.144     ]\n",
      "weights [-0.  0. -0. -0. -0. -0. -0. -0.]\n",
      "weights [-0. -0.  0. -0. -0.  0. -0.  0.]\n",
      "weights [-0.18        0.00090452  0.07967214  0.03818178 -0.13319154  0.07108794\n",
      " -0.0441162  -0.12000006]\n",
      "weights [-0. -0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.05294124 -0.0352764   0.0560655  -0.04909086 -0.18        0.03353202\n",
      " -0.16478226 -0.13800006]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.0741177   0.00633166  0.13868856 -0.0454545  -0.18        0.0303129\n",
      " -0.14510682  0.08400006]\n",
      "weights [ 0.05294124 -0.0352764   0.03245904  0.10000008  0.10510632  0.034605\n",
      " -0.01060632  0.108     ]\n",
      "weights [-0.03176478 -0.0334674   0.05016402 -0.03454542 -0.1595745   0.07055136\n",
      " -0.15187014 -0.054     ]\n",
      "weights [-0. -0. -0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.  0. -0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.13764708  0.01899504  0.0383607  -0.07454538 -0.12680856 -0.00616988\n",
      " -0.08469684 -0.144     ]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0.  0.  0.  0.]\n",
      "weights [-0.13764708  0.03165822  0.0855738  -0.11090916 -0.14978718 -0.04479876\n",
      " -0.14387706 -0.18      ]\n",
      "weights [-0.  0. -0. -0. -0. -0. -0. -0.]\n",
      "weights [ 0.  0.  0. -0. -0. -0. -0.  0.]\n",
      "weights [-0.13764708 -0.02623122  0.01180328 -0.18       -0.18        0.03245904\n",
      " -0.04903506 -0.144     ]\n",
      "weights [-0. -0.  0. -0. -0. -0.  0. -0.]\n",
      "weights [-0.09529416  0.04070358  0.02065572 -0.18       -0.18        0.00777944\n",
      " -0.1314261  -0.13199994]\n",
      "weights [-0.  0. -0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.15882354 -0.0081407   0.0383607  -0.10363644 -0.14893614 -0.04104324\n",
      " -0.08853966 -0.09      ]\n",
      "weights [-0. -0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.18        0.00452261  0.00885245 -0.01272728 -0.14680854  0.03782412\n",
      " -0.1157472  -0.18      ]\n",
      "weights [-0. -0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.09529416  0.0334674   0.02655738 -0.18       -0.18        0.05874822\n",
      " -0.0530316  -0.14999994]\n",
      "weights [-0. -0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.13764708 -0.0334674   0.03245904 -0.1254546  -0.14765958 -0.01850976\n",
      " -0.10790784 -0.15600006]\n",
      "weights [-0.  0. -0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.15882354 -0.01899504 -0.10918026 -0.11090916 -0.16936164 -0.03084948\n",
      " -0.1060632  -0.18      ]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [ 0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [ 0.09529416  0.01175879  0.02655738 -0.18       -0.18        0.00348734\n",
      " -0.15340734  0.00599999]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.15882354  0.09678384  0.06196716 -0.0272727   0.02638296  0.03782412\n",
      " -0.08638776 -0.16799994]\n",
      "weights [-0.  0. -0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.05294124  0.00452261  0.0855738  -0.03818178 -0.18        0.01153503\n",
      " -0.08838594 -0.13800006]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0.  0.]\n",
      "weights [-0.03176478  0.1076382   0.00885245 -0.18       -0.18       -0.03299544\n",
      " -0.14679756 -0.06600006]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.  0. -0. -0.  0.  0. -0. -0.]\n",
      "weights [-0.11647062  0.05155776  0.05016402 -0.18       -0.18       -0.06679584\n",
      " -0.15079428  0.02399994]\n",
      "weights [ 0.0741177   0.18       -0.0560655   0.0636363   0.18       -0.03997026\n",
      "  0.13880448  0.08400006]\n",
      "weights [ 0.  0. -0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.01058823 -0.02804022  0.0383607  -0.06727266 -0.18        0.0254844\n",
      " -0.1217421  -0.072     ]\n",
      "weights [ 0.11647062 -0.0750753   0.18        0.18        0.18        0.01904616\n",
      "  0.07501284  0.144     ]\n",
      "weights [-0.0741177   0.02623122  0.0383607  -0.18       -0.18       -0.04640832\n",
      " -0.0776259   0.036     ]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [ 0.0741177   0.00090452  0.06786882 -0.05999994 -0.13531914 -0.01904616\n",
      " -0.11697696 -0.03000006]\n",
      "weights [ 0.09529416 -0.08412066 -0.09147546  0.18        0.18        0.01260805\n",
      "  0.10913742 -0.05999994]\n",
      "weights [-0.15882354 -0.0334674   0.0383607  -0.03090906 -0.15574464  0.0684054\n",
      " -0.02351844 -0.11399994]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.15882354  0.01356784  0.03245904 -0.07090902 -0.14510646 -0.0147541\n",
      " -0.06579    -0.162     ]\n",
      "weights [-0.03176478 -0.05336676 -0.00295081  0.04909086  0.18       -0.04104324\n",
      "  0.12420162  0.07799994]\n",
      "weights [-0.09529416  0.0750753   0.0383607  -0.18       -0.18       -0.03192246\n",
      " -0.15448338 -0.06600006]\n",
      "weights [ 0.15882354 -0.1474371  -0.05016402  0.0272727   0.05531922 -0.034605\n",
      " -0.00138343  0.17400006]\n",
      "weights [ 0. -0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [ 0.05294124  0.0696483   0.04426236 -0.18       -0.18       -0.00187778\n",
      " -0.12742956 -0.09599994]\n",
      "weights [ 0.03176478 -0.1420101  -0.06786882  0.18        0.18       -0.0340686\n",
      "  0.1411101   0.05999994]\n",
      "weights [-0.13764708  0.10402002  0.0383607  -0.05272722  0.00723404  0.03138606\n",
      " -0.17139204 -0.126     ]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.13764708 -0.01718593  0.02655738 -0.11818188 -0.18       -0.03353202\n",
      " -0.17892396 -0.17400006]\n",
      "weights [ 0.01058823 -0.04613058 -0.1032786   0.18        0.18        0.18\n",
      "  0.15632784 -0.018     ]\n",
      "weights [-0.  0.  0. -0. -0.  0.  0. -0.]\n",
      "weights [-0.05294124  0.08050248  0.03245904 -0.0818181  -0.08297874  0.00187781\n",
      " -0.15279246 -0.06600006]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [ 0.03176478  0.00271357  0.04426236 -0.00545454 -0.10340424 -0.00348732\n",
      " -0.16570458  0.072     ]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0.  0.]\n",
      "weights [ 0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.18       -0.0388944   0.07967214 -0.07454538 -0.16297866  0.0179732\n",
      " -0.12527748 -0.18      ]\n",
      "weights [ 0.11647062 -0.13296474 -0.06786882  0.05999994 -0.02170206 -0.01153503\n",
      "  0.1523313   0.17400006]\n",
      "weights [-0.11647062  0.02442204 -0.03245904 -0.1436364  -0.14382972 -0.0217287\n",
      " -0.09576432 -0.15600006]\n",
      "weights [-0. -0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.13764708  0.01356784  0.0383607  -0.07090902 -0.13744674  0.00026825\n",
      " -0.1298889  -0.16799994]\n",
      "weights [-0.  0. -0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.09529416 -0.00994975  0.01180328 -0.10000008 -0.18       -0.0474813\n",
      " -0.16923996 -0.18      ]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0.  0.]\n",
      "weights [-0.18        0.03165822 -0.18       -0.18       -0.18        0.00134128\n",
      " -0.04872762 -0.04199994]\n",
      "weights [-0.  0. -0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.05294124 -0.00271357 -0.00885245 -0.05999994 -0.09914886  0.0024143\n",
      " -0.12589236 -0.04800006]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.09529416 -0.0081407  -0.00295081 -0.0636363  -0.18        0.00992551\n",
      " -0.14833476 -0.13800006]\n",
      "weights [-0. -0. -0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.  0. -0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.  0.  0. -0.  0. -0. -0.  0.]\n",
      "weights [-0.15882354 -0.05155776 -0.0383607  -0.11454552 -0.14765958 -0.07055136\n",
      " -0.14233986 -0.17400006]\n",
      "weights [-0.01058823 -0.0732663  -0.09737712  0.18        0.18        0.00456035\n",
      "  0.0791631   0.036     ]\n",
      "weights [-0.11647062 -0.00090452  0.00295081 -0.11090916 -0.14851062 -0.06304032\n",
      " -0.14910336 -0.14999994]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0.  0.]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.01058823 -0.00090452  0.06786882 -0.18       -0.18        0.00992551\n",
      " -0.13234842 -0.00599999]\n",
      "weights [-0. -0. -0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.13764708  0.04251258 -0.0383607  -0.0636363  -0.10978722  0.04587174\n",
      " -0.1120581  -0.14999994]\n",
      "weights [ 0.15882354 -0.05155776 -0.07967214  0.03818178  0.13319154 -0.01582713\n",
      "  0.02951316  0.08400006]\n",
      "weights [-0.13764708  0.0370854  -0.02065572 -0.18       -0.18       -0.03621456\n",
      " -0.12204954 -0.144     ]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [ 0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.13764708 -0.01899504  0.0855738  -0.07090902 -0.18       -0.00026825\n",
      " -0.147105   -0.054     ]\n",
      "weights [-0.  0. -0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.09529416  0.08592966  0.0383607  -0.08909082 -0.05531922  0.00724293\n",
      " -0.13280958 -0.126     ]\n",
      "weights [ 0.13764708 -0.08412066 -0.02655738  0.04181814  0.02680848  0.0297765\n",
      "  0.14018796  0.13199994]\n",
      "weights [-0.03176478  0.00994975 -0.18       -0.18       -0.18       -0.18\n",
      " -0.14510682 -0.162     ]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0.  0.]\n",
      "weights [-0.15882354  0.00090452  0.0147541  -0.1254546  -0.15617016 -0.05338296\n",
      " -0.0896157  -0.14999994]\n",
      "weights [ 0.0741177  -0.02261304 -0.0147541   0.18        0.18       -0.02280186\n",
      "  0.15187014  0.05999994]\n",
      "weights [-0.09529416 -0.02984922  0.07377048 -0.11090916 -0.18       -0.02280186\n",
      " -0.14326218 -0.10200006]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.  0. -0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.15882354  0.0696483   0.06196716 -0.18       -0.18        0.03514158\n",
      " -0.15571314 -0.13800006]\n",
      "weights [-0. -0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.05294124  0.15105528  0.09737712 -0.18       -0.18        0.0388971\n",
      "  0.03258756 -0.036     ]\n",
      "weights [-0. -0. -0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.13764708  0.0750753  -0.00885245 -0.05636358 -0.125532   -0.04372578\n",
      " -0.08454312 -0.162     ]\n",
      "weights [ 0.09529416 -0.15105528  0.18        0.18        0.18        0.02763036\n",
      "  0.15940224  0.09      ]\n",
      "weights [ 0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.09529416  0.03165822  0.00885245 -0.0818181  -0.12893616 -0.00187778\n",
      " -0.15663528 -0.162     ]\n",
      "weights [-0. -0. -0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.15882354  0.07869348  0.07377048 -0.07090902 -0.03957444 -0.01850976\n",
      " -0.05487624 -0.16799994]\n",
      "weights [ 0.05294124 -0.08773866 -0.03245904  0.05272722  0.18       -0.00026825\n",
      "  0.0956106   0.00599999]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0. -0.  0. -0.]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.0741177   0.08592966  0.05016402 -0.18       -0.18        0.00080478\n",
      " -0.15847992  0.08400006]\n",
      "weights [ 0.03176478 -0.08592966 -0.04426236  0.18        0.18       -0.03138606\n",
      "  0.15248502  0.04800006]\n",
      "weights [-0.15882354 -0.05155776  0.00295081 -0.18       -0.18       -0.06304032\n",
      " -0.12804444 -0.14999994]\n",
      "weights [ 0.13764708 -0.10040202  0.02655738  0.0818181  -0.04978728 -0.02763036\n",
      "  0.15509826  0.15600006]\n",
      "weights [-0.18        0.00994975  0.00885245 -0.03090906 -0.11957454  0.0426528\n",
      " -0.16539714 -0.17400006]\n",
      "weights [ 0.15882354 -0.04070358 -0.00885245  0.0636363   0.11361708 -0.00831595\n",
      "  0.08561916  0.126     ]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.03176478  0.02623122  0.04426236 -0.11818188 -0.13319154 -0.05230998\n",
      " -0.12035862 -0.12000006]\n",
      "weights [-0.01058823 -0.12934674 -0.14459022  0.09272736  0.07787232 -0.06357672\n",
      "  0.08116146 -0.018     ]\n",
      "weights [-0.  0.  0. -0. -0.  0.  0. -0.]\n",
      "weights [ 0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.18        0.03165822  0.0147541  -0.06727266 -0.10000008 -0.0147541\n",
      " -0.11620836 -0.17400006]\n",
      "weights [-0. -0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0. -0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [ 0.01058823 -0.01899504  0.00295081 -0.18       -0.18       -0.05928462\n",
      " -0.17016228 -0.108     ]\n",
      "weights [-0.03176478 -0.02804022  0.18        0.18        0.18        0.18\n",
      "  0.15187014  0.126     ]\n",
      "weights [-0.15882354  0.02080404  0.00295081 -0.13272732 -0.1025532  -0.051237\n",
      " -0.17077716 -0.16799994]\n",
      "weights [ 0.18       -0.06422112 -0.02065572  0.0272727   0.07361694 -0.0469449\n",
      "  0.1358838   0.162     ]\n",
      "weights [-0. -0. -0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.13764708 -0.04613058 -0.18       -0.18       -0.18       -0.18\n",
      " -0.1763109  -0.17400006]\n",
      "weights [-0. -0. -0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.13764708  0.02261304  0.04131144 -0.0636363  -0.18        0.01153503\n",
      " -0.16923996 -0.18      ]\n",
      "weights [-0.  0. -0. -0. -0. -0. -0. -0.]\n",
      "weights [ 0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [ 0.09529416  0.01175879  0.03245904  0.01636364 -0.18        0.01636364\n",
      " -0.16462854 -0.036     ]\n",
      "weights [-0.  0. -0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.11647062 -0.00090452  0.0560655  -0.14000004 -0.152766   -0.07645302\n",
      " -0.14833476 -0.126     ]\n",
      "weights [ 0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.18        0.05336676  0.0560655  -0.18       -0.18       -0.01260805\n",
      " -0.08392824 -0.13199994]\n",
      "weights [ 0.11647062 -0.13839192 -0.07377048  0.0818181   0.11361708  0.00134128\n",
      "  0.0146029  -0.00599999]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0.  0.]\n",
      "weights [-0.18        0.04974876  0.0560655  -0.0454545  -0.09063828  0.0147541\n",
      " -0.06840306 -0.16799994]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.13764708 -0.01356784  0.00295081 -0.07818174 -0.18       -0.010462\n",
      " -0.17200692 -0.162     ]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.15882354  0.00090452  0.03245904 -0.13636368 -0.1502127  -0.04426236\n",
      " -0.09084546 -0.13800006]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.18       -0.00090452 -0.18       -0.18       -0.18       -0.04587174\n",
      " -0.1530999  -0.17400006]\n",
      "weights [-0. -0. -0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.  0. -0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.05294124  0.06783912 -0.18       -0.18       -0.05016384 -0.1687788\n",
      "  0.02399994  0.        ]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.13764708  0.01537688  0.00295081 -0.0636363  -0.15617016 -0.04479876\n",
      " -0.17231418 -0.18      ]\n",
      "weights [ 0.18       -0.1456281  -0.0855738   0.08545446  0.14170212 -0.01582713\n",
      "  0.14372334  0.09599994]\n",
      "weights [-0.0741177   0.0388944   0.03245904 -0.09636372 -0.1323405  -0.03943368\n",
      " -0.15432966 -0.126     ]\n",
      "weights [-0. -0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [ 0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0.  0.]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0.  0.]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.15882354  0.00633166  0.0560655  -0.14000004 -0.14510646 -0.07591662\n",
      " -0.1165158  -0.17400006]\n",
      "weights [-0.01058823 -0.11668338 -0.06786882  0.10363644  0.18        0.0147541\n",
      "  0.0642528   0.11399994]\n",
      "weights [-0.18       -0.01537688  0.0560655  -0.18       -0.18       -0.00616988\n",
      " -0.09960714 -0.144     ]\n",
      "weights [ 0.11647062 -0.05879394 -0.0560655   0.18        0.18       -0.00456037\n",
      "  0.13019634  0.04199994]\n",
      "weights [-0.15882354 -0.03165822  0.00885245 -0.13272732 -0.13957452 -0.06625926\n",
      " -0.12819816 -0.16799994]\n",
      "weights [ 0.11647062 -0.1058292  -0.04426236  0.04909086  0.07574472  0.010462\n",
      "  0.0611784   0.13800006]\n",
      "weights [-0.05294124  0.02080404  0.00885245 -0.03818178 -0.18        0.00348734\n",
      " -0.15202386 -0.162     ]\n",
      "weights [-0.  0.  0.  0. -0.  0. -0. -0.]\n",
      "weights [-0.09529416  0.06783912  0.06786882 -0.18       -0.18       -0.01260805\n",
      " -0.15325362 -0.126     ]\n",
      "weights [-0.  0. -0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.0741177  -0.04070358  0.06196716 -0.03090906 -0.16212762  0.01207154\n",
      " -0.1680102  -0.09599994]\n",
      "weights [-0.01058823 -0.11668338 -0.05016402  0.18        0.18        0.00402385\n",
      "  0.16923996  0.036     ]\n",
      "weights [ 0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.15882354  0.10402002  0.03245904 -0.10363644 -0.10851066 -0.0426528\n",
      " -0.17308278 -0.162     ]\n",
      "weights [-0.09529416 -0.09497484 -0.0855738   0.05999994  0.16765956  0.03621456\n",
      "  0.07962426  0.04800006]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.11647062 -0.0388944   0.02655738 -0.18       -0.18       -0.00563337\n",
      " -0.15048684 -0.072     ]\n",
      "weights [ 0.01058823 -0.15648246 -0.0855738   0.05272722  0.0842553  -0.00509688\n",
      "  0.1269684   0.08400006]\n",
      "weights [-0.15882354  0.02984922  0.02655738 -0.07818174 -0.18       -0.03299544\n",
      " -0.160632   -0.18      ]\n",
      "weights [ 0.15882354 -0.17457282 -0.04426236  0.04909086  0.07404264 -0.01582713\n",
      "  0.0574893   0.13199994]\n",
      "weights [-0.15882354  0.00271357 -0.03245904 -0.1254546  -0.16468092 -0.05016384\n",
      " -0.11113578 -0.14999994]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.13764708  0.00271357 -0.00885245 -0.11818188 -0.06723396 -0.05016384\n",
      " -0.09760896 -0.16799994]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.13764708 -0.05155776  0.02655738 -0.0818181  -0.18       -0.0297765\n",
      " -0.10191294 -0.17400006]\n",
      "weights [-0.  0.  0. -0. -0.  0. -0. -0.]\n",
      "weights [-0.05294124  0.00633166  0.0147541  -0.18       -0.18       -0.04962744\n",
      " -0.15371478 -0.13199994]\n",
      "weights [-0. -0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.13764708  0.0714573   0.04131144 -0.18       -0.18       -0.0426528\n",
      " -0.16631946 -0.13199994]\n",
      "weights [-0. -0.  0. -0. -0.  0. -0.  0.]\n",
      "weights [-0.11647062  0.07688448  0.0560655  -0.1254546  -0.18       -0.00616988\n",
      " -0.16124688  0.072     ]\n",
      "weights [ 0.0741177  -0.16190946 -0.00885245  0.05999994  0.04170204  0.01260805\n",
      "  0.1023741   0.13199994]\n",
      "weights [-0.15882354 -0.18       -0.0383607  -0.1072728  -0.18       -0.0474813\n",
      " -0.17046972 -0.17400006]\n",
      "weights [-0. -0. -0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.01058823  0.02261304  0.03245904 -0.18       -0.18       -0.05338296\n",
      " -0.06286932  0.04199994]\n",
      "weights [-0. -0. -0. -0. -0. -0.  0. -0.]\n",
      "weights [-0.  0.  0. -0.  0. -0. -0.  0.]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n",
      "weights [-0.11647062  0.02984922  0.0383607  -0.1254546  -0.13531914 -0.0388971\n",
      " -0.1755423  -0.162     ]\n",
      "weights [-0.  0.  0. -0. -0. -0. -0. -0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.,  0.,  0., -0., -0., -0., -0., -0.])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "N=X_train.columns\n",
    "\n",
    "global weights\n",
    "weights= np.random.randint(N)# initialize weights to zero\n",
    "           \n",
    "def pcr_predict(inputs):\n",
    "        # predicts the label of one training example input with current weights\n",
    "        #print(\"inputs , self.weights\",inputs,self.weights[0:])\n",
    "        summation = np.dot(inputs, weights[0:]) \n",
    "        #print(\"summation\",summation)\n",
    "        if summation > 0:\n",
    "            activation = 1\n",
    "        else:\n",
    "            activation = -1            \n",
    "        return activation\n",
    "\n",
    "def pcr_train(train_inputs, labels,epoch=50,rate=0.09):\n",
    "    # trains perceptron weights on training dataset\n",
    "    global weights\n",
    "    labels = np.expand_dims(labels, axis=1)\n",
    "    data = np.hstack((train_inputs.values,labels))\n",
    "        #print(\"lables\",labels)\n",
    "        #print(\"data\",data)\n",
    "    for row in data:\n",
    "        inputs = row[:-1]\n",
    "        label = row[-1]\n",
    "        prediction = pcr_predict(inputs)\n",
    "        #print(\"prediction\",prediction)\n",
    "        #weights[0:] += \n",
    "        #print(type(weights))\n",
    "        weights = ((rate * (label - prediction) * inputs))\n",
    "        print(\"weights\",weights)\n",
    "        #self.weights[0] += \n",
    "        #print(\"weigths2\",rate * (label - prediction))\n",
    "    return weights\n",
    "        \n",
    "\n",
    "def pcr_evaluate(test_inputs, labels):\n",
    "    # calculates average prediction error on testing dataset\n",
    "    errors = []\n",
    "    predict=[]\n",
    "    for inputs, label in zip(test_inputs, labels):\n",
    "        prediction = pcr_predict(inputs)\n",
    "        predict.append(prediction)\n",
    "        errors.append(np.abs(label-prediction))\n",
    "            #print(errors)\n",
    "    return predict\n",
    "\n",
    "\n",
    "\n",
    "pcr_train(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "26e2adfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.329004329004329"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predic = pcr_evaluate(X_test.values,y_test)\n",
    "accuracy_score(y_test,y_predic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5eab95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
